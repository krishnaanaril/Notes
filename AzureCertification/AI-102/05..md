# Create a Language Understanding solution with Azure Cognitive Services

- For a more visual method of building, training, and deploying your language model, you can use **Language Studio**.
- You can split entities into a few different component types:
    - **Learned** entities are the most flexible kind of entity.
    - **List** entities are useful when you need an entity with a specific set of possible values
    - **Prebuilt** entities are useful for common types such as numbers, datetimes, and names. 
- When you teach your model with each different type of utterance, the Language service can learn how to categorize intents correctly based off format and punctuation.
- You can have up to five prebuilt components per entity. Using prebuilt model elements can significantly reduce the time it takes to develop a language understanding solution.
- Language service features fall into two categories: Pre-configured features, and Learned features. Learned features require building and training a model to correctly predict appropriate labels.
- Pre-configured features include:
    - Summarization
    - Named entity recognition
    - Personally identifiable information (PII) detection
    - Key phrase extraction
    - Sentiment analysis
    - Language detection
- **Conversational language understanding (CLU)** is one of the core custom features offered by Azure Cognitive Services for Language. CLU helps users to build custom natural language understanding models to predict overall intent and extract important information from incoming utterances.
- The container image for the specific Cognitive Services API you want to use is downloaded and deployed to a container host, such as a local Docker server, an Azure Container Instance (ACI), or Azure Kubernetes Service (AKS).