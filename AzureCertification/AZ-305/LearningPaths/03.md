# AZ-305: Design data storage solutions

## Design a data storage solution for non-relational data
- You may need one storage account for each location.
- A storage account by itself has no financial cost.
-  The types of storage accounts are:
    | Storage Account |	Supported Services |
    |-----------------|--------------------|
    |Standard general-purpose v2 |	Blob (including Data Lake Storage), Queue, and Table storage, Azure Files|
    |Premium block blobs |	Blob storage (including Data Lake Storage) |
    |Premium file shares |	Azure Files |
    |Premium page blobs	| Page blobs only |
- The paired secondary region is determined based on the primary region and can't be changed. 
- Optimize storage costs by placing your data in the appropriate access tier.
    - Premium - Uses SSD
    - Hot 
    - Cold
    - Archive
- Immutable storage for Azure Blob Storage enables users to store business-critical data in a WORM (Write Once, Read Many) state. Policies are applied at the container level and audit logs are available.
- Immutable storage for Azure Blob storage supports two types of immutability policies.
    - Time-based retention policies
    - Legal hold policies
- A legal hold is a temporary immutability policy that can be applied for legal investigation purposes or general protection policies. 
- Use a legal hold when the period of time that the data must be kept in a WORM state is unknown.
- Azure Files can be used to add to or replace a company's existing on-premises NAS devices or file servers.
- Azure file shares can be used in two ways: by directly mounting these serverless Azure file shares (SMB) or by caching Azure file shares on-premises using Azure File Sync.
- Azure Files offers four different tiers of storage, premium, transaction optimized, hot, and cool. 
- NetApp Files is a fully managed, highly available, enterprise-grade NAS service. 
- Data disks are used by virtual machines to store data. Each data disk has a maximum capacity of 32,767 GB.
- Azure offers several types of data disks. 
    - Ultra-disk
    - Premium SSD
    - Standard SSD
    - Standard HDD
- Ultra-disk storage may not be available in all regions. Premium SSD storage is available in all regions.
- You can attach Standard SSD/HDD disks to any VM.
- Disk Caching isn’t supported for disks 4 TiB and larger.
- Changing the cache setting of an Azure disk detaches and reattaches the target disk. When it’s the operating system disk, the VM is restarted.
- There are several encryption types available for your managed disks. Encryption types includes Azure Disk Encryption (ADE), Server-Side Encryption (SSE) and encryption at host.
- Service endpoints enables on-premises networks to access resources using NAT IP addresses.
- Azure Storage encryption offers two options for managing encryption keys at the level of the storage account:
    - Microsoft-managed keys. 
    - Customer-managed keys - Customer-managed keys must be stored in Azure Key Vault. 

## Design a data storage solution for relational data
- Azure offers SQL Server in the following ways:
    - SQL Server on Azure VMs
    - Managed instances:
        - Single instances
        - Instance pool
    - Databases:
        - Single database
        - Elastic pool
- Azure SQL Database is a PaaS deployment option of Azure SQL that abstracts both the OS and the SQL Server instance.
- SQL Elastic Pool enable you to buy a set of compute and storage resources that are shared among all the databases in the pool.
- Azure SQL Database has two purchasing models: vCore and DTU,
- vCores stands for Virtual cores.
- The vCore-based model is recommended because it allows you to independently select compute and storage resources. The DTU-based model is a bundled measure of compute, storage, and I/O resources.
- Service tiers available to Azure SQL Database and SQL Managed Instance are - General Purpose and Business Critical.
- Azure SQL Managed Instance is a PaaS deployment option of Azure SQL.
- Data changes made on the primary replica propagate to read-only replicas asynchronously.
-  The **shard map manager** is a special database that maintains global mapping information about all shards (databases) in a shard set. The metadata allows an application to connect to the correct database, based upon the value of the sharding key.
- You can equate the DTU model's Basic and Standard tiers to General Purpose, and its Premium tiers to Business Critical.
- Unlike in the General Purpose tier, in Business Critical, the data and log files are all running on direct-attached SSD, which significantly reduces network latency.
-   | DATA STATE	| ENCRYPTION METHOD| 
    |---------------|------------------|
    | Data-at-rest	| TDE, Always Encrypted| 
    | Data-in-motion	| SSL/TLS, Always Encrypted| 
    | Data-in-process	| Dynamic data masking| 
- TDE performs encryption and decryption of the data at the page level.
- **Dynamic data masking** is a policy-based security feature that hides the sensitive data in the result set of a query over designated database fields, while the data in the database is not changed. 
- Note that Dynamic Data Masking is a presentation layer feature, and unmasked data can always be viewed by administrators.
- Always Encrypted is a feature designed to protect sensitive data stored in specific database columns from access (for example, credit card numbers, national identification numbers, etc.)
- Always Encrypted does not work with Dynamic Data Masking. It is not possible to encrypt and mask the same column. 
- Azure SQL Edge is an optimized relational database engine geared for IoT and IoT Edge deployments.
- Azure Cosmos DB is a fully managed NoSQL database service for modern app development. It has single-digit millisecond response times and guaranteed speed at any scale.
- Azure Cosmos DB is flexible and stores data in atom-record-sequence (ARS) format. 
- SQL Server in an Azure VM allows for Windows authentication.
- Azure SQL Managed Instance is the only PaaS service that supports instance-scoped features like CLR and Service Broker.

## Design data integration
- Azure Data Factory is a cloud-based ETL and data integration service that can help you create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores. 
- You can use Azure Data Factory to: 
    - Orchestrate data movement.
    - Transform data at scale.
- There are four major steps in creating and implementing a data-driven workflow in Azure Data Factory:
    - Connect & Collect
    - Transform & Enrich
    - Continuous integration and delivery (CI/CD) and publish
    - Monitor 
- Azure Data factory has the following components: 
    - Pipelines and activities
    - Datasets 
    - Linked services 
    - Data Flows
    - Integration Runtimes
- A data lake is a repository of data that is stored in its natural format, usually as blobs or files.
- Data Lake Storage Gen2 builds on Azure Blob storage capabilities to optimize it specifically for analytics workloads.
- The current implementation of Azure's data lake storage service is Azure Data Lake Storage Gen2.
- Azure Data Lake Storage can work with structured, semi-structured, and unstructured data.
- Azure Data Lake Storage is priced at Azure Blob Storage levels.
- Azure Data Lake Storage is primarily designed to work with Hadoop and all frameworks that use the Apache Hadoop Distributed File System (HDFS) as their data access layer.
- The Azure Data Lake Storage access control model supports both Azure role-based access control (RBAC) and Portable Operating System Interface for UNIX (POSIX) access control lists (ACLs).
- Azure Databricks is a fully managed, cloud-based Big Data and Machine Learning platform
- Azure Databricks offers three environments for developing data intensive applications: Databricks SQL, Databricks Data Science & Engineering, and Databricks Machine Learning.
- Azure Databricks has a Control plane and a Data plane.
- **Azure Synapse Analytics** leverages a massively parallel processing (MPP) architecture. This architecture includes a control node and a pool of compute nodes.
- Azure Synapse Analytics uses a technology named **PolyBase** that enables you to retrieve and query data from relational and non-relational sources. 
- Azure Synapse Analytics is composed of the following elements:
    - Synapse SQL pool
    - Synapse Spark pool
    - Synapse Pipelines
    - Synapse Link
    - Synapse Studio
- Synapse SQL offers both serverless and dedicated resource models to work with using node-based architecture.
- The warm data path is about analyzing as the data flows through the system. We process this stream in near-real time, save it to the warm storage, and push it to the analytics clients.
- The cold path includes the batch layer and the serving layers. The combination provides a long-term view of the system.
- Azure Stream Analytics works on the following concepts: Data stream & Event Processing.
- Azure Stream Analytics supports processing events in CSV, JSON and Avro data formats.
